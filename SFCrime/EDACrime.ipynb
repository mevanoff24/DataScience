{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Classification\n",
    "### Exploratory Data Analysis and Predicting the category of crimes that occurred in the city by the bay\n",
    "\n",
    "From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz.\n",
    "\n",
    "Today, the city is known more for its tech scene than its criminal past. But, with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity of crime in the city by the bay.\n",
    "\n",
    "From Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred.\n",
    "\n",
    "What can we learn about the city through visualizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in train and test\n",
    "train = pd.read_csv('train 2.csv')\n",
    "test = pd.read_csv('test 2.csv')\n",
    "# combine both for a couple of visualizations\n",
    "dat = pd.concat([train, test], axis = 0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Dates'] = pd.to_datetime(train.Dates)\n",
    "train['Day'] = train.Dates.dt.day\n",
    "train['Month'] = train.Dates.dt.month\n",
    "train['Minute'] = train.Dates.dt.minute\n",
    "train['Hour'] = train.Dates.dt.hour\n",
    "train['Year'] = train.Dates.dt.year\n",
    "train['Week'] = train.Dates.dt.week\n",
    "train['MonthDay'] = train.Dates.map(lambda x: x.strftime(\"%m-%d\"))\n",
    "train['YearDay'] = train.Dates.map(lambda x: x.strftime(\"%y-%d\"))\n",
    "train['YearMonth'] = train.Dates.map(lambda x: x.strftime(\"%y-%m\"))\n",
    "train['Event'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pluck out the season of each crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_season(row):\n",
    "    if row in [5, 6, 7]:\n",
    "        return 'summer'\n",
    "    if row in [8, 9, 10]:\n",
    "        return 'fall'\n",
    "    if row in [11, 0, 1]:\n",
    "        return 'winter'\n",
    "    if row in [2, 3, 4]:\n",
    "        return 'spring'\n",
    "    \n",
    "train['Season'] = train['Month'].map(get_season) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine All Data to show the total number of crimes per day and per month. The spikes in the Year Day are just how the train adn test sets are split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we use the combined data of train and test sets just for this illistration\n",
    "dat['Dates'] = pd.to_datetime(dat.Dates)\n",
    "dat['Event'] = 1\n",
    "\n",
    "dat['YearMonth'] = dat.Dates.map(lambda x: x.strftime(\"%y-%m\"))\n",
    "yearMonth = dat[['Event', 'YearMonth']].groupby(['YearMonth']).count()\n",
    "yearMonth.columns = ['Crimes']\n",
    "# rolling mean by year\n",
    "yearMonth['Rolling Mean'] = pd.rolling_mean(yearMonth.Crimes, 12)\n",
    "\n",
    "dat['YearDay'] = dat.Dates.map(lambda x: x.strftime(\"%y-%d\"))\n",
    "yearDay = dat[['Event', 'YearDay']].groupby(['YearDay']).count()\n",
    "yearDay.columns = ['Crimes']\n",
    "# rolling mean by 2 weeks\n",
    "yearDay['Rolling Mean'] = pd.rolling_mean(yearDay.Crimes, 14)\n",
    "\n",
    "yearDay.plot(figsize = (18, 6))\n",
    "plt.title('Total Crimes Grouped By Day')\n",
    "plt.ylabel('Number of Crimes')\n",
    "plt.tight_layout()\n",
    "\n",
    "yearMonth.plot(figsize = (18, 6))\n",
    "plt.title('Total Crimes Grouped By Month')\n",
    "plt.ylabel('Number of Crimes')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories\n",
    "\n",
    "#### This is the predictor in the dataset\n",
    "We will only be using the training set from now on later, we will predict this variable, but first we will take a deep look at the `Category` column and the other columns used to predict this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at total count of crimes for each criminal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Category.value_counts().plot(kind = 'barh', figsize = (15,10))\n",
    "plt.title('Crimes By Category')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kernel Density Plots for each crime type in the dataset to visually show where these crimes occur in the city. First we load in an open street map, so we can later overlay the data on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in map and set coordinates for map\n",
    "mapdata = np.loadtxt(\"sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "asp = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "\n",
    "# subset to 300000 for time purposes \n",
    "fac_train = train.dropna()\n",
    "fac_train = fac_train[1:300000] \n",
    "\n",
    "# seaborn FacetGrid, split by crime Category\n",
    "g= sns.FacetGrid(fac_train, col = 'Category', col_wrap = 5, size = 6, aspect = 1 / asp)\n",
    "\n",
    "# show the background map\n",
    "for ax in g.axes:\n",
    "    ax.imshow(mapdata, cmap = plt.get_cmap('gray'), \n",
    "              extent = lon_lat_box, \n",
    "              aspect = asp)\n",
    "    \n",
    "# Kernel Density Estimate plot\n",
    "g.map(sns.kdeplot, 'X', 'Y', clip = clipsize)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will dive deeper into the categories and the map and show individual crime incidents for the desired category. The draw_map function takes in a dataframe and an optional desired category to subset the search, while the second plot_amount function takes in a dataframe, category, and timeline and produces a line plot showing the number of crimes grouped per desired time interval along with a desired moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "def draw_map(df, subset=None, state_boundries=True, fill_land=False):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    # Create a map\n",
    "    map = Basemap(projection='cyl', resolution = 'h', llcrnrlon = -122.5247, llcrnrlat = 37.699,\n",
    "                urcrnrlon = -122.3366, urcrnrlat = 37.8299, lat_0=37.752303, lon_0=-122.445576)\n",
    "    \n",
    "    # Draw state boundries on the map\n",
    "    if state_boundries == True:\n",
    "        map.drawstates()\n",
    "        \n",
    "    # Draw the coastlines on the map\n",
    "#     map.drawcoastlines()\n",
    "\n",
    "    # Draw country borders on the map\n",
    "#     map.drawcountries()\n",
    "\n",
    "    # Fill the land with grey\n",
    "    if fill_land == True:\n",
    "        map.fillcontinents(color = '#888888')\n",
    "\n",
    "    # Draw the map boundaries\n",
    "#     map.drawmapboundary(fill_color = '#f4f4f4')\n",
    "\n",
    "    # Define our subset, longitude and latitude points \n",
    "    df = df[df['Category'] == subset]\n",
    "    x, y = map(df['X'].values, df['Y'].values)\n",
    "    \n",
    "    # Overlay open street map\n",
    "    mapdata = np.loadtxt(\"sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "    lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "    asp = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "    plt.imshow(mapdata, extent = lon_lat_box, aspect = asp, cmap=plt.get_cmap('gray'))\n",
    "    map.plot(x, y, 'bo')\n",
    "\n",
    "    # Show the map\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_amount(df, subset, roll_num, group):\n",
    "    df['Event'] = 1\n",
    "    df = df[df.Category == subset]\n",
    "\n",
    "    df = df[['Event', group]].groupby([group]).count()\n",
    "    df.columns = ['Crimes']\n",
    "    # rolling mean\n",
    "    df['Rolling Mean'] = pd.rolling_mean(df.Crimes, roll_num)\n",
    "\n",
    "    df.plot(figsize = (18, 6))\n",
    "    plt.title('Total Crimes Grouped By Month')\n",
    "    plt.ylabel('Number of Crimes')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at a few of the individual categories\n",
    "\n",
    "##### Prostitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_map(train, 'PROSTITUTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prostitution grouped my month with 12 month moving average\n",
    "plot_amount(train, 'PROSTITUTION', 12, 'YearMonth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suicide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_map(train, 'SUICIDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# suicide grouped by month with 12 month moving average\n",
    "plot_amount(train, 'SUICIDE', 12, 'YearMonth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the peak for one of the months is statistically different than the others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sm\n",
    "\n",
    "# whats that peak \n",
    "suicide_df = train[train.Category == 'SUICIDE']\n",
    "suicide_aug_2009 = suicide_df[(suicide_df.Year == 2009) & (suicide_df.Month == 8)]\n",
    "highest_number = suicide_aug_2009[['Month', 'Event']].groupby('Month').count().values\n",
    "\n",
    "# t test for the peak modeling the samples as a Poisson distribution\n",
    "num_occ_suicide = suicide_df[['YearMonth', 'Event']].groupby('YearMonth').count().reset_index().Event.values\n",
    "rvs = sm.poisson.rvs(mu = num_occ_suicide, loc = num_occ_suicide)\n",
    "t_test = sm.ttest_1samp(rvs, highest_number)\n",
    "print 'The T-Stat for August 2009 is:', t_test.statistic[0][0]\n",
    "print 'P-Value for August 2009 is:', t_test.pvalue[0][0], 'which is significant'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drunkenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_map(train, 'DRUNKENNESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drunkenness grouped my day with 2 week moving average\n",
    "plot_amount(train, 'DRUNKENNESS', 14, 'YearDay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vehicle Theft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use kde as scatter plot is too dense\n",
    "vehicle_theft = train[train.Category == 'VEHICLE THEFT']\n",
    "lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "clipsize = [[-122.5247, -122.3366],[ 37.699, 37.8299]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20 * asp))\n",
    "ax = sns.kdeplot(vehicle_theft.X, vehicle_theft.Y, clip = clipsize, aspect = 1 / asp)\n",
    "ax.imshow(mapdata, cmap = plt.get_cmap('gray'), \n",
    "              extent = lon_lat_box, aspect = asp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # vehicle theft grouped my day with 2 week moving average\n",
    "plot_amount(train, 'VEHICLE THEFT', 14, 'YearDay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is interesting. The drop around the year 2006 is peculiar, so lets take a deeper look into this category. So with this category, lets look at the Description tag and try to determine what is going on here. This function analyses each description and if the words associated with a stolen vehicle are involved, we assign the new created  column with stolen or not stolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stolen_map(row):\n",
    "    for item in ['STOLEN','GRAND THEFT','RENTAL']:\n",
    "        if item in row:\n",
    "            return 'Stolen'\n",
    "        else:\n",
    "            return 'Not Stolen'\n",
    "        \n",
    "vehicle_theft['Stolen'] = train.Descript.map(stolen_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there were a lot of vehicle recoveries that were no longer reported after 2006. There were zero 'Not Stolen' vehicles after around 2007 with only a couple in the year 2006 Not Stolen So before when we calculated “vehicle thefts per day” we ended up with twice as many cars being “stolen” prior to 2006. Perhaps this can be determined by a different classification tactic by the police."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stolen = vehicle_theft[vehicle_theft.Stolen == 'Stolen']\n",
    "not_stolen = vehicle_theft[vehicle_theft.Stolen != 'Stolen']\n",
    "\n",
    "ax = not_stolen[['YearDay', 'Event']].groupby('YearDay').count().plot(figsize = (18, 6), \n",
    "                                                                 title = 'Not Stolen in VEHICLE THEFT')\n",
    "stolen[['YearDay', 'Event']].groupby('YearDay').count().plot(figsize = (18, 6), \n",
    "                                                                  title = 'Stolen By Day in VEHICLE THEFT', ax = ax)\n",
    "\n",
    "plt.title('Stolen By Day(Blue) and Not Stolen(Red) in VEHICLE THEFT')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visuallize this with bar charts to show the types of incidents. As yu can see from this plot that all of 2006 and later consisted of 'stolen' related incidents, while pre 2006 consisted of a wider range of incidents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,4))\n",
    "vehicle_theft['post2006'] = np.where(vehicle_theft.Year >= 2006, 1, 0)\n",
    "\n",
    "sns.countplot('Descript', hue = 'post2006', data = vehicle_theft)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Description For Vehicile Theft Pre and Post 2006')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cna also look at the term `recovered` in the description. It look as the same phenomenal as the stolen category and after 2006 this term must have been changed for another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vehicle_theft['Recovered'] = vehicle_theft.Descript.map(lambda x: 1 if 'recovered' in x.lower() else 0)\n",
    "recovered = vehicle_theft[vehicle_theft.Recovered == 1]\n",
    "recovered[['YearDay', 'Event']].groupby('YearDay').count().plot(figsize = (18, 4), title = 'Recovered in VEHICLE THEFT')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now take a look at the different type of crimes and classify them into white collar, blue collar, and other crimes. With this we can visualize the different type of areas associated with each type of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_crime = [\"FRAUD\", \"FORGERY/COUNTERFEITING\", \"BAD CHECKS\" , \"EXTORTION\", \"EMBEZZLEMENT\", \"SUSPICIOUS OCC\",\n",
    "              \"BRIBERY\"]\n",
    "\n",
    "blue_crime = [\"VANDALISM\", \"LARCENY/THEFT\", \"STOLEN PROPERTY\", \"ROBBERY\", \"DRIVING UNDER THE INFLUENCE\",\n",
    "             \"DISORDERLY CONDUCT\", \"LIQUOR LAWS\", \"VEHICLE THEFT\", \"ASSAULT\", \"KIDNAPPING\", \"TRESPASS\", \n",
    "             \"ARSON\", \"RECOVERED VEHICLE\"]\n",
    "             \n",
    "other_crime = [\"MISSING PERSON\", \"RUNAWAY\", \"FAMILY OFFENSES\", \"SEX OFFENSES NON FORCIBLE\",\n",
    "             \"PORNOGRAPHY/OBSCENE MAT\", \"WEAPON LAWS\", \"DRUNKENNESS\", \"SUICIDE\", \"TREA\",\n",
    "             \"DRUG/NARCOTIC\", \"SEX OFFENSES FORCIBLE\",  \"LOITERING\"]\n",
    "\n",
    "def collar_crimes(row):\n",
    "    for white in white_crime:\n",
    "        if white in row:\n",
    "            return 'white collar'\n",
    "    for blue in blue_crime:\n",
    "        if blue in row:\n",
    "            return 'blue collar'\n",
    "    for other in other_crime:\n",
    "        if other in row:\n",
    "            return 'other'\n",
    "    return 'misc'\n",
    "        \n",
    "\n",
    "train['collar'] = train.Category.map(collar_crimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facet Grid with a KDE with each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fac_train = train.dropna()\n",
    "fac_train = fac_train[1:300000] \n",
    "\n",
    "g = sns.FacetGrid(fac_train, col = 'collar', col_wrap = 2, size = 4, aspect = 1 / asp)\n",
    "\n",
    "# Show the background map\n",
    "for ax in g.axes:\n",
    "    ax.imshow(mapdata, cmap = plt.get_cmap('gray'), \n",
    "              extent = lon_lat_box, \n",
    "              aspect = asp)\n",
    "# Kernel Density Estimate plot\n",
    "g.map(sns.kdeplot, 'X', 'Y', clip = clipsize)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Time interval for the different types of crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_collar = train[train.collar == 'white collar']\n",
    "blue_collar = train[train.collar == 'blue collar']\n",
    "other_collar = train[train.collar == 'other']\n",
    "\n",
    "ax = white_collar[['YearDay', 'Event']].groupby('YearDay').count().plot(figsize=(18, 4), label = 'white')\n",
    "blue_collar[['YearDay', 'Event']].groupby('YearDay').count().plot(ax = ax)\n",
    "other_collar[['YearDay', 'Event']].groupby('YearDay').count().plot(ax = ax)\n",
    "plt.title('Blue - White Collar, Red - White Collar, Purple - Other')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category `OTHER OFFENSES` in the predictive category. Other Offenses is broken down by word in this word cloud to get an idea of the keywords contained in the crimes that were not high enough to obtain their own category. The word in the cloud are the words that appear in the Description Column. It looks like most of the `OTHER OFFENSES` are related to trafic violations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordCloud of OTHER OFFENSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# subset column\n",
    "other_offense_df = train[train.Category == 'OTHER OFFENSES']\n",
    "# combine all words and remove commas \n",
    "other_offense_words = ' '.join(list(other_offense_df.Descript)).replace(',', '')\n",
    "# create word cloud\n",
    "wordcloud = WordCloud(stopwords = STOPWORDS, background_color = 'grey', \n",
    "                      width = 1600, height = 800).generate(other_offense_words)\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Only in train, so can't be for prediction, but it still can be analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['GrandTheft'] = train.Descript.map(lambda x: 1 if 'theft' in x.lower() else 0)\n",
    "print 'Percent of Grand Theft:', train.GrandTheft.sum() / train.shape[0]\n",
    "\n",
    "# percent charged with some type of grand theft\n",
    "grand_theft = train[train.GrandTheft == 1]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.countplot('PdDistrict', hue = 'DayOfWeek', data = grand_theft)\n",
    "plt.title('Theft Count Per District Per Day of Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def auto_related(row):\n",
    "    for item in ['AUTO', 'LICENSE', 'AUTOMOBILE', 'VEHICLES', 'TRAFFIC']:\n",
    "        if item in row:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "train['Automobile'] = train.Descript.map(auto_related)\n",
    "auto = train[train.Automobile == 1]\n",
    "print 'Percent in dataset:', train.Automobile.sum() / train.shape[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "auto.Category.value_counts().plot(kind = 'bar')\n",
    "plt.subplot(1,2,2)\n",
    "(auto.DayOfWeek.value_counts() / auto.shape[0]).plot(kind = 'bar')\n",
    "plt.title('Auto Related Categories')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "descript_dtm = vect.fit_transform(train.Descript)\n",
    "\n",
    "term_df = pd.DataFrame(descript_dtm.toarray())\n",
    "term_df.columns = vect.get_feature_names()\n",
    "\n",
    "train_dtm = train.join(term_df)\n",
    "train_dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot any single term in term frequency dataframe and plot the number of occurances per desired time interval. I choose to plot a few, however there is over 900 terms in this dataframe and anything can be ploted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_term(term, cat, typ):\n",
    "    # find similiar words if searched word is not in df, simple way\n",
    "    similiar_words = [word for word in train_dtm.columns if word.startswith(term[0])]\n",
    "    if term in term_df.columns:\n",
    "        # easy way to use tf idf vectorizer for word counter as well\n",
    "        df = train_dtm[train_dtm[term] > 0]\n",
    "        # normalized bar plot\n",
    "        if typ == 'bar':\n",
    "            if df.shape[0] > 0:\n",
    "                (df[cat].value_counts() / df.shape[0]).plot(kind = 'bar', \n",
    "                                        title = '{}: Number of instances: {}'.format(term.upper(), df.shape[0]))\n",
    "                plt.ylabel('Percent')\n",
    "            else:\n",
    "                print 'empty dataframe, try one of these!'\n",
    "                print similiar_words\n",
    "        # line plot \n",
    "        else:\n",
    "            df[[cat, 'Event']].groupby(cat).count().plot(figsize=(18,4))\n",
    "            plt.title('{}: Number of instances: {}'.format(term.upper(), df.shape[0]))\n",
    "            plt.tight_layout()   \n",
    "    else:\n",
    "        print 'term not in dataframe, try one of these!'\n",
    "        print similiar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the trifecta of `Sex`, `Money`, `Drugs` By day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets look at sex, money, and drugs\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,3,1)\n",
    "find_term('sex', 'DayOfWeek', 'bar')\n",
    "plt.subplot(1,3,2)\n",
    "find_term('money', 'DayOfWeek', 'bar')\n",
    "plt.subplot(1,3,3)\n",
    "find_term('drugs', 'DayOfWeek', 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And By Year and Month. With these plot youo can definitely see that there is high varity between days of the week(above) and the month and year for these three categories. The `Sex` term seem consistant other than a couple of jumps, however the money realted terms jump heavily after the year 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_term('sex', 'YearMonth', 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# big jump after 2009\n",
    "find_term('money', 'YearMonth', 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_term('drugs', 'YearMonth', 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD District\n",
    "\n",
    "This is an interesting category as it is the name of the Police Department District where the crime occurred. First we will plot the count and percent of crimes in each Police District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "ax = sns.countplot(\"PdDistrict\", data = train, order = [i for i in train.PdDistrict.value_counts().keys()])\n",
    "plt.title('Bar Plot of District with Percent')\n",
    "# make twin axis\n",
    "ax2=ax.twinx()\n",
    "# switch so count axis is on right, frequency on left\n",
    "ax2.yaxis.tick_left()\n",
    "ax.yaxis.tick_right()\n",
    "# switch the labels over\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax2.yaxis.set_label_position('left')\n",
    "ax2.set_ylabel('Frequency [%]')\n",
    "\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100.0 * y / train.shape[0]), (x.mean(), y), \n",
    "            ha = 'center', va = 'bottom') \n",
    "\n",
    "# fix the frequency range\n",
    "ax2.set_ylim(0,100)\n",
    "ax.set_ylim(0,ncount)\n",
    "ax2.grid(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the 10 most common Crime Categories based on the Police District. This is a good representation of the combination of the amount and type of crime per district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ten_most_common = train[train['Category'].isin(train['Category'].value_counts()[:10].index)]\n",
    "ten_most_crime_by_district = pd.crosstab(ten_most_common.PdDistrict, ten_most_common.Category)\n",
    "ten_most_crime_by_district.plot(kind = 'barh', figsize=(14, 10), stacked = True, colormap = 'Reds')\n",
    "plt.title('Disbribution of the City-wide Ten Most Common Crimes in Each District')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show line plots of each police district normalized by the total amount of crimes per district. We do this so the higher crime areas do not look higher than the lower ones. Thefore all of the districts are all on the same scale and we can really see the highest crime rates per desired time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalized by desired time interval, very jankey way of doing this \n",
    "def normilzed_district_plot(cat):\n",
    "    first_g = train[['PdDistrict', cat, 'Event']].groupby(['PdDistrict', cat]).count().reset_index()\n",
    "    second_g = first_g.groupby('PdDistrict').sum()\n",
    "    total_per_district = second_g.Event\n",
    "    total_dict = dict(total_per_district)\n",
    "\n",
    "    total_df = pd.DataFrame.from_dict(total_dict.items())\n",
    "    total_df.columns = ['PdDistrict', 'Count']\n",
    "    total_df = pd.concat([total_df, total_df, total_df, total_df, total_df, total_df, total_df ,total_df], ignore_index=True) \n",
    "    total_df = pd.concat([total_df, total_df, total_df], ignore_index=True)\n",
    "    total_df = total_df.sort(['PdDistrict']).reset_index()\n",
    "    total_df.drop('index', inplace = True, axis = 1)\n",
    "    \n",
    "    first_g['Norm'] = first_g['Event'] / total_df['Count']\n",
    "    first_g.pivot(cat, 'PdDistrict', 'Norm').plot(figsize = (18,4))\n",
    "    plt.title('PdDistrict by {}'.format(cat))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By hour. Makes sense that the lowest would be in the middle of the night, interesting the peak at about noon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normilzed_district_plot('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Minute. Interesting as most reports are probabily rounded by nearest hour and easy interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normilzed_district_plot('Minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Year. And you can see the `Tenderloin` had a big peak between the years 2007 - 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normilzed_district_plot('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is disecting the address column. Here we pick out three things. First if the address contains the world block, second we pick out the ending address like `ST`, or `AV`, or `RD`. And lastly we find the `/` character showing that the crime occurred on a street corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Block'] = train.Address.map(lambda x: 1 if 'block' in x.lower() else 0).astype(np.float64)\n",
    "train['EndAddress'] = train.Address.map(lambda x: x[-2:])\n",
    "train['Intersection'] = train.Address.map(lambda x: 1 if '/' in x else 0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that the top 3 categories switched in these two plots of intersection crimes, by having other offensises surpass larceny/theft. And non-criminal pass other when there is the term block in the address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_subset(row, cat, top):\n",
    "    df = train[train[row] == 1]\n",
    "    df[cat].value_counts()[:top].plot(kind = 'bar')\n",
    "    plt.title('Top {} for {} and {}'.format(top, row.upper(), cat))\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Crime Categories')\n",
    "    \n",
    "plt.figure(figsize=(18,4))    \n",
    "plt.subplot(1,2,1)  \n",
    "plot_subset('Intersection', 'Category', 10)\n",
    "plt.subplot(1,2,2)    \n",
    "plot_subset('Block', 'Category', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the Crimes Percent by ending address. However, not too informative for our purposes, but an interesting visualization. Is there really that many roads labelled `ST` in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_address = train[['EndAddress', 'Event']].groupby(['EndAddress']).count()\n",
    "(end_address.Event / train.shape[0]).plot(kind = 'bar', figsize = (14,4))\n",
    "plt.title('Crimes Percent By Ending Street Address')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Log Odd for Address Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example \n",
    "logodds2['800 Block of BRYANT ST'].plot(kind = 'barh', figsize = (10,5))\n",
    "plt.title('Log Odds for Address')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution\n",
    "\n",
    "This is also not in the test dataset, as it is how the crime incident was resolved. However, a couple interesting things can be seen. First off, over 60% of the crimes, no action was taken. Some lenient cops! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train.Resolution.value_counts() / train.shape[0]).plot(kind = 'barh', figsize = (10,5))\n",
    "plt.title('Crime Resolutions')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can look at what Police Districts seemed to take more actions than others. This plot is really interesting as the only police district that took more actions than not is the `TENDERLOIN`. And the amount is not even close here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "train['NoResolution'] = train.Resolution.map(lambda x: 'NoActionTaken' if x == 'NONE' else 'ActionTaken')\n",
    "sns.countplot('PdDistrict', hue = 'NoResolution', data = train)\n",
    "plt.title('Action Taken in Crime Per District')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see this lets take a little deeper dive into the `TENDERLOIN` police district and find out which crimes are contributing to this. It looks at the are more drugs/narcotics with higher churn rates and less larceny/thefts and other petty thefts that might be let go more often. This police district might be focusing more drug rated incidents than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tenderloin pdDistrict\n",
    "tenderloin = train[train.PdDistrict == 'TENDERLOIN']\n",
    "tenderloin = tenderloin.groupby(['Category', 'NoResolution'])['Category'].count().unstack('NoResolution').fillna(0)\n",
    "tenderloin[['ActionTaken','NoActionTaken']].plot(kind='bar', figsize=(14, 6), title = 'Tenderloin Crimes')\n",
    "\n",
    "# all other pdDistricts\n",
    "not_tenderloin = train[train.PdDistrict != 'TENDERLOIN']\n",
    "not_tenderloin = not_tenderloin.groupby(['Category', 'NoResolution'])['Category'].count().unstack('NoResolution').fillna(0)\n",
    "not_tenderloin[['ActionTaken','NoActionTaken']].plot(kind='bar', figsize=(14, 6), title = 'Not Tenderloin Crimes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can try and look at the Juveniles that were atleast book and cited in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Juvenile'] = train.Resolution.map(lambda x: 1 if 'juvenile' in x.lower() else 0)\n",
    "# how many issued juveniles in data set\n",
    "print 'Percent of Juvinile in data that were atleast booked {:.2f}%'.format((train.Juvenile.sum() / train.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is not a hug subset of the data it is interesting the the summer break months are lower than the school months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "juvinile = train[train.Juvenile == 1]\n",
    "juvinile['Event'] = 1\n",
    "\n",
    "non_juvinile = train[train.Juvenile != 1]\n",
    "non_juvinile['Event'] = 1\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "juvinile[['Month', 'Event']].groupby(['Month']).count().plot(kind = 'bar', ax = axs[0], figsize = (12,4), \n",
    "                                                            title = 'Juvinile Booked Crimes Per Month')\n",
    "\n",
    "non_juvinile[['Month', 'Event']].groupby(['Month']).count().plot(kind = 'bar', ax = axs[1],\n",
    "                                                            title = 'Non Juvinile Booked Crimes Per Month')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "After performing Exploratory Data Analysis and dtermining some important predicotrs for predicting the crime category, it is now time to the perform machine learning pipeline. Note some of this will be the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# first clear variables for memory issues\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in data\n",
    "train = pd.read_csv('train 2.csv')\n",
    "test = pd.read_csv('test 2.csv')\n",
    "\n",
    "# drop columns not in test\n",
    "train.drop(['Descript', 'Resolution'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfrom Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dat in (train, test):\n",
    "    dat['Dates'] = pd.to_datetime(dat.Dates)\n",
    "    dat['Day'] = dat.Dates.dt.day\n",
    "    dat['Month'] = dat.Dates.dt.month\n",
    "    dat['Minute'] = dat.Dates.dt.minute\n",
    "    dat['Hour'] = dat.Dates.dt.hour\n",
    "    dat['Year'] = dat.Dates.dt.year\n",
    "    dat['Week'] = dat.Dates.dt.week\n",
    "    dat.drop(['Dates'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_season_binary(row):\n",
    "    summer, fall, winter, spring = 0, 0, 0, 0\n",
    "    if row in [5, 6, 7]:\n",
    "        summer = 1\n",
    "    if row in [8, 9, 10]:\n",
    "        fall = 1\n",
    "    if row in [11, 0, 1]:\n",
    "        winter = 1\n",
    "    if row in [2, 3, 4]:\n",
    "        spring = 1\n",
    "    return summer, fall, winter, spring\n",
    "\n",
    "for dat in (train, test):\n",
    "    dat['Summer'], dat['Fall'], dat['Winter'], dat['Spring'] = zip(*dat['Month'].apply(get_season_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address - Add 1 for column if `block` occurs in address and add 1 if it is at an intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dat in (train, test):\n",
    "    dat['Block'] = dat.Address.map(lambda x: 1 if 'block' in x.lower() else 0).astype(np.float64)\n",
    "    dat['Intersection'] = dat.Address.map(lambda x: 1 if '/' in x else 0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding - Dummy Variables for `DayOfWeek` and `PdDistrict`. I have always liked using pandas get_dummies method over a sklearn implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_vars = ['PdDistrict', 'DayOfWeek']\n",
    "\n",
    "for dummy in dummy_vars:\n",
    "    dummies = pd.get_dummies(train[dummy])\n",
    "    train = train.join(dummies)\n",
    "    dummies = pd.get_dummies(test[dummy])\n",
    "    test = test.join(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Address and recently created dummy varibales fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dat in (train, test):\n",
    "    dat.drop(['DayOfWeek', 'PdDistrict'], axis = 1, inplace = True)\n",
    "    dat.drop(['Address'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform `Category` field to numeric integers, just another way of doing LabelEncoder from sklearn with a 1 to 1 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_crimes = train['Category'].value_counts().index.order()\n",
    "map_values_dic = pd.Series(range(0, len(ordered_crimes)), index = ordered_crimes).to_dict()\n",
    "\n",
    "train['Category'] = train['Category'].map(map_values_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into X without the independant variable, y the independant variable, and final test (not to be used till the end) while droping the `Id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "y = X.pop('Category').values\n",
    "X = X.values\n",
    "test = test.drop('Id', axis = 1).copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets from the original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658536, 31) (219513, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100)\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple classifier function that in a desired classifier and optional probability paramater if predicted probabilities are desired. We will fit the classifier, predict with the classifier and we will print out both the classification accuracy (number of correctly predicted categories divided by the total number) and the log loss (negitive expected log probability) in terms of using predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "def simple_classifier(clf, probability=False):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    if probability:\n",
    "        pred_train = clf.predict_proba(X_train)\n",
    "        pred_test = clf.predict_proba(X_test)\n",
    "    else:\n",
    "        pred_train = clf.predict(X_train)\n",
    "        pred_test = clf.predict(X_test) \n",
    "\n",
    "    # for the normal person, classification accuracy \n",
    "    clf_train = clf.score(X_train, y_train)\n",
    "    clf_test = clf.score(X_test, y_test)\n",
    "    print '{} train/test classification accuracies: {:.3f}/{:.3f}'.format(\n",
    "        clf.__class__.__name__, clf_train, clf_test)\n",
    "\n",
    "    # for the statistician, log loss - negative expected log probability\n",
    "    # -log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "    clf_train_logloss = log_loss(y_train, pred_train)\n",
    "    clf_test_logloss = log_loss(y_test, pred_test)\n",
    "    print '{} train/test log los:s {:.3f}/{:.3f}'.format(\n",
    "        clf.__class__.__name__, clf_train_logloss, clf_test_logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Logistic Regression with a couple of hyperparamaters to reduce the complexity of the model, just to get an idea of what we are dealing with here. Here, it is obvious that a single linear separator is not going to be the answer to such a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=100, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(penalty = 'l2', C = 0.01, \n",
    "                          random_state = 100)\n",
    "\n",
    "simple_classifier(log_reg, probability = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search to find the best C parameter for model complexity, the Inverse of regularization strength with L2. We then can use this found parameter later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'C' : [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "clf = LogisticRegression(penalty = 'l2')\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, cv = 3, scoring = 'log_loss')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I would try a Support Vector Machine, however with its O(n*3) runtime, it would not be reasonable for my purposes, especially if I need to use parameter tuning with grid search, randomized grid search would help but still way too computationally expensive. So lets try an Simple Decision Tree that might work better with our type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier train/test classification accuracies: 0.883/0.242\n",
      "DecisionTreeClassifier train/test log los:s 0.180/25.421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', \n",
    "                              max_depth = None)\n",
    "\n",
    "simple_classifier(tree, probability = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do some parameter tuning and visualizing for our Decision Tree Classifier. Here we compute the traing and testing scores for each n_estimator with cross validation, by default StratifiedKFold is used for multiclass classification. Next we will plot the plot the accuracy scores with a confidene interval. Here we can tell that the best max_depth is 10. Plotting the validation curve can be a useful trick to determine rather than using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAGRCAYAAACwi/grAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6qypsr8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103cec650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.figure(figsize = (14, 6))\n",
    "\n",
    "# initialize random forest\n",
    "tree = DecisionTreeClassifier()\n",
    "# set param range for n_estimators\n",
    "param_range = [1, 3, 5, 10, 15, 20]\n",
    "\n",
    "# create training / testing scores for n_estimators with cross validation\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator = tree, \n",
    "                X = X_train, \n",
    "                y = y_train, \n",
    "                param_name = 'max_depth', \n",
    "                param_range = param_range,\n",
    "                cv = 3,\n",
    "                scoring = 'accuracy')\n",
    "\n",
    "# get mean and std for scores\n",
    "train_mean = np.mean(train_scores, axis = 1)\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "\n",
    "# plot training points\n",
    "plt.plot(param_range, train_mean, \n",
    "         color = 'blue', marker = 'o', \n",
    "         markersize = 5, label = 'training accuracy')\n",
    "\n",
    "# plot training confidence intervals\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha = 0.15,\n",
    "                 color = 'blue')\n",
    "\n",
    "# plot testing points\n",
    "plt.plot(param_range, test_mean, \n",
    "         color = 'green', linestyle = '--', \n",
    "         marker = 's', markersize = 5, \n",
    "         label = 'validation accuracy')\n",
    "\n",
    "# plot testing confidence intervals\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha = 0.15, color = 'green')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Decision Tree Validation Curve')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets combine some trees with a built in ensemble classifier with a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier train/test classification accuracies: 0.883/0.308\n",
      "RandomForestClassifier train/test log los:s 0.461/6.371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 100)\n",
    "\n",
    "simple_classifier(rf, probability = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The king of Ensembles, Voting Classifier. Weighted Majority Vote based on class probabilities. This will allows us to combine different classification algorithms associated with the individual weights of each classifier. It then becomes a good meta-classifier that balances out individual classifiers weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import operator\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, classifiers, vote = 'classlabel', weights = None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "       \n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\"\n",
    "                             % vote)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d classifiers'\n",
    "                             % (len(self.weights), len(self.classifiers)))\n",
    "\n",
    "        # Use LabelEncoder to ensure class labels start with 0, which\n",
    "        # is important for np.argmax call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:  # 'classlabel' vote\n",
    "\n",
    "            #  Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in self.classifiers_]).T\n",
    "\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the classifers we have previously tried alone. So we use a Logistic Regression, Random Forest, and Decision Classifier and use the majority voting technique to evaluate the new classifer and see if we can improve on our basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier train/test classification accuracies: 0.806/0.319\n",
      "Voting Classifier train/test log loss: 1.235/2.323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "clf1 = LogisticRegression(penalty = 'l2', \n",
    "                          C = 0.01, \n",
    "                          random_state = 100)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators = 50, \n",
    "                              random_state = 100)\n",
    "\n",
    "clf3 = DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(\n",
    "                classifiers=[clf1, clf2, clf3], vote = 'probability')\n",
    "\n",
    "mv_clf.fit(X_train, y_train)\n",
    "pred_train = mv_clf.predict_proba(X_train)\n",
    "pred_test = mv_clf.predict_proba(X_test)\n",
    "\n",
    "clf_train = mv_clf.score(X_train, y_train)\n",
    "clf_test = mv_clf.score(X_test, y_test)\n",
    "print 'Voting Classifier train/test classification accuracies: {:.3f}/{:.3f}'.format(clf_train, clf_test)\n",
    "\n",
    "clf_train_logloss = log_loss(y_train, pred_train)\n",
    "clf_test_logloss = log_loss(y_test, pred_test)\n",
    "print 'Voting Classifier train/test log loss: {:.3f}/{:.3f}'.format(clf_train_logloss, clf_test_logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we can try the king of all classification techniques, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier train/test log los:s 2.289/2.325\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {'objective': 'multi:softprob', 'num_class': len(np.unique(y_train))}\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "X_test_xgb = xgb.DMatrix(X_test)\n",
    "\n",
    "xgb = xgb.train(param_grid, X_train_xgb, 20)\n",
    "\n",
    "pred_train = xgb.predict(X_train_xgb)\n",
    "pred_test = xgb.predict(X_test_xgb)\n",
    "\n",
    "# print 'Testing Set Log Loss:', log_loss(y_test, pred) # 0.51542415268\n",
    "xgb_train_logloss = log_loss(y_train, pred_train)\n",
    "xgb_test_logloss = log_loss(y_test, pred_test)\n",
    "print 'XGBoost train/test log loss: {:.3f}/{:.3f}'.format(xgb_train_logloss, xgb_test_logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting All Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Weighted Majority Vote ensemble method on all of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier classification accuracies with all training data: 0.783\n",
      "Voting Classifier log loss with all training data: 1.252\n"
     ]
    }
   ],
   "source": [
    "# run on all training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "clf1 = LogisticRegression(penalty = 'l2', \n",
    "                          C = 0.01, \n",
    "                          random_state = 100)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators = 50, \n",
    "                              random_state = 100)\n",
    "\n",
    "clf3 = DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(\n",
    "                classifiers=[clf1, clf2, clf3], vote = 'probability')\n",
    "\n",
    "mv_clf.fit(X, y)\n",
    "pred_train = mv_clf.predict_proba(X)\n",
    "pred = mv_clf.predict_proba(test)\n",
    "\n",
    "clf_train = mv_clf.score(X, y)\n",
    "print 'Voting Classifier classification accuracies with all training data: {:.3f}'.format(\n",
    "                                                                clf_train)\n",
    "clf_train_logloss = log_loss(y, pred_train)\n",
    "print 'Voting Classifier log loss with all training data: {:.3f}'.format(\n",
    "                                                                clf_train_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "# Create submission to kaggle\n",
    "i = 0\n",
    "\n",
    "with gzip.open('crimesEDA5.csv.gz', 'wt') as outf:\n",
    "    fo = csv.writer(outf, lineterminator='\\n')\n",
    "    fo.writerow(['Id'] + list(ordered_crimes))\n",
    "    for i, pr in enumerate(pred):\n",
    "        fo.writerow([i] + list(pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a xgboost on all of the training data. This results in a Multi-Class Loss of 2.32902 on the withheld Kaggle test set, 72nd of 1077 at the time of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {'objective': 'multi:softprob', 'num_class': len(np.unique(y))}\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(X, y)\n",
    "X_test_xgb = xgb.DMatrix(X_test)\n",
    "\n",
    "xgb = xgb.train(param_grid, X_train_xgb, 20)\n",
    "\n",
    "pred_train = xgb.predict(X)\n",
    "pred = xgb.predict(X_test_xgb)\n",
    "\n",
    "xgb_train_logloss = log_loss(y, pred_train)\n",
    "print 'XGBoost log loss with all training data: {:.3f}'.format(xgb_train_logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "# Create submission to kaggle\n",
    "i = 0\n",
    "\n",
    "with gzip.open('crimesEDA4.csv.gz', 'wt') as outf:\n",
    "    fo = csv.writer(outf, lineterminator='\\n')\n",
    "    fo.writerow(['Id'] + list(ordered_crimes))\n",
    "    for i, pr in enumerate(pred):\n",
    "        fo.writerow([i] + list(pr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
